{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A pipeline for recording, processing & successfully merging e-phys, IMU and tracking data (v3.0.0).\n",
    "### author: github/bartulem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 0]** Considerations before, during and after conducting the experiments.\n",
    "\n",
    "1. Set up [SpikeGLX](https://billkarsh.github.io/SpikeGLX/) to accommodate your specific recording configuration.\n",
    "2. Turn on and calibrate the IMU before every session (system calibration does not need to be 3, but others do before the rat is plugged on; time readings should not have duplicates either).\n",
    "3. Open Motive.\n",
    "- Check whether the system is calibrated (continuous calibration should be on).\n",
    "- If necessary, for each camera change strobe light settings to continuous light.\n",
    "- Check that the rigid bodies for the head & arena LEDs exist (this enables on-line automatic labeling).\n",
    "- Check whether the acquisition directory is the correct one.\n",
    "- Check whether camera 1 is recording in MJPG/greyscale mode.\n",
    "4. Put three circular markers on the back of the animal and plug it on.\n",
    "5. Conduct the recording.\n",
    "- In the NPX, tracking and IMU acquisition programs, you should see the microcontroller-generated random LED pulses.\n",
    "- If the data acquisition looks OK in SpikeGLX, start recording.\n",
    "- Start acquiring data on the IMU.\n",
    "- Start recording in Motive.\n",
    "- Keep it going for some time (e.g. 20-25 min).\n",
    "- Stop recording in Motive.\n",
    "- Stop acquiring data on the IMU.\n",
    "- Stop recording in SpikeGLX.\n",
    "6. It's good practice to label the back points immediately in Motive (the head & LEDs should be labeled already, if step 3d was implemented) and export the data in a .csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 1]** Merge Neuropixel sessions to run Kilosort2. This step is *optional*, you can skip it if you are interested in only one session.\n",
    "\n",
    "As instance attributes, you determine:\n",
    "1. the directories where the NPX .bin files are (all associated files should be in the same directory; also, make sure they're named in a way that will order them properly)\n",
    "2. the desired paths to the future merged files\n",
    "3. the desired paths to the future .pkl files\n",
    "\n",
    "Thus, multiple unrelated data streams can be processed sequentially.\n",
    "\n",
    "As inputs to the concat_npx function, note that you have the option to set:\n",
    "1. file_type (concatenate lf or ap files; defaults to ap)\n",
    "2. cmd_prompt (whether to do the merging through the terminal/cmd prompt; defaults to True)\n",
    "3. nchan (the number of channels on the probe; defaults to 385)\n",
    "4. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "\n",
    "Along with the merged file, this code outputs a .pkl file with information about changepoints of the merged sessions (necessary for extracting spike times later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import concatenate\n",
    "\n",
    "file_directories = [r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\spikes_imec0']\n",
    "new_file_names = [r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\spikes_imec0\\060520_distal_all_g0_t0.imec0.ap.bin']\n",
    "pkl_lengths = [r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\060520_distal_all_g0_t0.imec0.ap.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_dir, new_file_name, pkl_len in zip(file_directories, new_file_names, pkl_lengths):\n",
    "    concatClass = concatenate.Concat(file_dir, new_file_name, pkl_len)\n",
    "    concatClass.concat_npx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 2]** Run Kilosort2 through Python.\n",
    "\n",
    "This step assumes you are happy with *everything* in the config file. If you need to modify anything, either the code needs to change or you complete this step in Matlab.\n",
    "If this doesn't bother you, then you should do the following:\n",
    "1. Download/clone [Kilosort2](https://github.com/MouseLand/Kilosort2) and set up the config, master and CUDA files accordingly.\n",
    "2. Install [matlab engine](https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html) (as an admin!).\n",
    "3. Kilosort2 runs on all the .bin files in the given directory below. Make sure that this is what you want.\n",
    "4. Don't use my Kilosort2 directory, but rather your own (created in step 0).\n",
    "5. Set the file and Kilosort2 directories, and run the cell below.\n",
    "\n",
    "!NB: While Kilosort2 is running, it's a good opportunity to label the tracking data if you haven't done so already!\n",
    "\n",
    "As inputs to the run_kilosort function, note that you have to set:\n",
    "1. file_dir (the absolute path to the directory the binary file is in)\n",
    "2. kilosort2_dir (the absolute path to the directory the Kilosort2 code is in)\n",
    "\n",
    "You, therefore, run one binary file at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import kilosort\n",
    "\n",
    "file_dir = r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\spikes_imec0'\n",
    "kilosort2_dir = r'A:\\group\\bartulm\\Kilosort2-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kilosort.run_kilosort(file_dir, kilosort2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 3]** Arbitrate what is noise and what are clusters in Phy.\n",
    "1. Install Phy: [Phy v2.0](https://github.com/cortex-lab/phy)\n",
    "2. Navigate to the directory where Kilosort2 results were saved, open powershell and type \"cmd\", followed by \"activate phy2\", followed by \"phy template-gui params.py\".\n",
    "3. Complete the manual curation ([Phy tutorial](https://phy.readthedocs.io/en/latest/)) and save your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 4]** Read in the sync events (make sure the PC has enough memory to run this, say 64Gb RAM) and put them in separate .txt files.\n",
    "\n",
    "If you haven't done so already, label the tracked rigid bodies and marker sets in Motive (read the tutorial if you need) and export the data:\n",
    "1. File > Export Tracking Data.\n",
    "2. The following options need to be OFF: (1) Unlabeled markers, (2) Rigid Bodies, (3) Rigid Body markers, (4) Bones, (5) Bone markers.\n",
    "3. Click \"Export\" and you should have created a .csv file (it may take ~1 minute).\n",
    "\n",
    "As instance attributes, you determine:\n",
    "1. the list with the files whose sync events you'd like to read (in practice this would be the imec0 and imec1 files for a given recording session)\n",
    "2. the absolute path of the future sync .pkl file\n",
    "\n",
    "As inputs to the read_se function, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. sync_chan (the specific sync port channel on the probe; defaults to 385)\n",
    "3. track_file (the absolute path to the tracking file for that session; defaults to 0)\n",
    "4. imu_file (the absolute path to the IMU file for that session; defaults to 0)\n",
    "5. imu_pkl (the absolute future path to the IMU dataframe .pkl file; defaults to 0)\n",
    "6. jitter_samples (number of samples in the imec data across which LED jitter could arise; defaults to 3)\n",
    "7. half_smooth_window (number of frames in the tracking data is smoothed over to correct nans in fully empty frames; defaults to 10)\n",
    "8. ground_probe (in a multi probe setting, the probe other probes are synced to - if you only have imec1, this needs to be set to 1; defaults to 0)\n",
    "9. frame_rate (the tracking camera frame rate for that session; defaults to 120)\n",
    "10. npx_sampling_rate (the sampling rate of the NPX system; defaults to 3e4)\n",
    "11. sync_sequence (the length of the sequence the LED events should be matched across data streams; defaults to 10)\n",
    "12. sample_error (the time the presumed IMEC/IMU LEDs could be allowed to err around; defaults to 20 (ms))\n",
    "13. which_imu_time (the IMU time to be used in the analyses, loop.starttime (0) or sample.time (1); defaults to 1)\n",
    "\n",
    "Therefore, you proceed one recording session at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import reader\n",
    "\n",
    "npx_files = [r'D:\\SGL_DATA\\test_100520\\distal_s2_sound_g0\\distal_s2_sound_g0_imec1\\distal_s2_sound_g0_t0.imec1.ap.bin']\n",
    "track_file = r'A:\\store\\Bartul\\neuropixel\\test_100520\\Sound\\Take 2020-05-10 01.15.15 PM.csv'\n",
    "imu_file = r'A:\\store\\Bartul\\neuropixel\\test_100520\\Sound\\CoolTerm Capture 2020-05-10 13-15-20.txt'\n",
    "sync_df = r'A:\\store\\Bartul\\neuropixel\\test_100520\\Sound\\sync_df_100520_s2.pkl'\n",
    "imu_pkl = r'A:\\store\\Bartul\\neuropixel\\test_100520\\Sound\\CoolTerm Capture 2020-05-10 13-15-20.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "readClass = reader.EventReader(npx_files, sync_df)\n",
    "readClass.read_se(track_file=track_file, imu_file=imu_file, imu_pkl=imu_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 5]** Load the sync data from the .pkl file(s) and analyze how well the tracking/IMU data are synced with NPX data.\n",
    "\n",
    "Before running this step, make sure you have [plotly](https://plotly.com/python/getting-started/?utm_source=mailchimp-jan-2015&utm_medium=email&utm_campaign=generalemail-jan2015&utm_term=bubble-chart) installed.\n",
    "\n",
    "You set the absolute paths to:\n",
    "1. the sync_df .pkl files\n",
    "\n",
    "Thus, multiple files can be processed in sequence.\n",
    "\n",
    "As inputs to the estimate_sync_quality function, note that you have the option to set:\n",
    "1. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "2. to_plot (plot or not to plot y_test and y_test_prediction statistics; defaults to False)\n",
    "3. ground_probe (in a multi probe setting, the probe other probes are synced to; defaults to 0)\n",
    "4. imu_files (the list of absolute paths to imu_pkl files that contain the raw IMU data; defaults to 0)\n",
    "5. which_imu_time (the IMU time to be used in the analyses, loop.starttime (0) or sample.time (1); defaults to 1)\n",
    "\n",
    "The imu_files should be ordered such that the first sync file corresponds to the IMU file of the same session, and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import synchronize\n",
    "\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\test_100520\\No_sound\\sync_df_100520_s1.pkl']\n",
    "imu_files = [r'A:\\store\\Bartul\\neuropixel\\test_100520\\No_sound\\CoolTerm Capture 2020-05-10 12-31-19.pkl']\n",
    "to_plot = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syncClass = synchronize.Sync(sync_pkls)\n",
    "syncClass.estimate_sync_quality(to_plot=to_plot, imu_files=imu_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 6]** Split clusters back into individual sessions and get spike times. This step should be completed irrespective of the number of sorted sessions.\n",
    "\n",
    "Variable the_dirs is a list of directories where Kilosort2 results are stored for each recording probe (processing one recording day in one go).\n",
    "\n",
    "As inputs to the split_cluster function, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. one_session (whether you have only one session; defaults to True)\n",
    "3. min_spikes (the minimum number of spikes in one session to consider the cluster worthy of saving; defaults to 100)\n",
    "4. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "5. ground_probe (in a multi probe setting, the probe other probes are synced to; defaults to 0)\n",
    "6. to_plot (plot or not to plot y_test and y_test_prediction statistics; defaults to False)\n",
    "7. sync_pkls (paths to as many sync .pkl files as there are recording sessions; defaults to 0)\n",
    "8. pkl_lengths (.pkl files that have information about where concatenated files were stitched together; defaults to 0)\n",
    "9. print_details (whether or not to print details about spikes in every individual cluster; defaults to 0)\n",
    "\n",
    "!NB: make sure each directory has the imec ID in the name!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import spikes2sessions\n",
    "\n",
    "the_dirs = [r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\spikes_imec0']\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\05022020_both_distal_g0_t0.imec0.ap.pkl']\n",
    "pkl_lengths = [r'A:\\store\\Bartul\\neuropixel\\26148_bruno\\060520\\060520_distal_all_g0_t0.imec0.ap.pkl']\n",
    "nchan = 385\n",
    "one_session = 0\n",
    "min_spikes = 100\n",
    "to_plot = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sstClass = spikes2sessions.ExtractSpikes(the_dirs)\n",
    "sstClass.split_clusters(one_session=one_session, min_spikes=min_spikes, nchan=nchan, pkl_lengths=pkl_lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 7]** Create .pkl file for GUI.\n",
    "\n",
    "As instance attributes, you determine:\n",
    "1. the absolute paths where the .csv (tracking) files are (tracking files with the appendage \"final\" should be used!)\n",
    "2. the absolute paths where the .pkl (sync event) files are\n",
    "\n",
    "Thus, multiple files can be processed in sequence. Every GUI .pkl file is saved to the same directory as the tracking .csv file.\n",
    "\n",
    "!NB: The rat-cam is meant to be used for the raw tracking video, which should be exported to match the sequence from the start of first to the start of the last LED event!\n",
    "\n",
    "As inputs to the csv_to_pkl function, note that you have the option to set:\n",
    "1. frame_rate (you set it manually, otherwise it's read from the sync .pkl file)\n",
    "2. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "3. ground_probe (in a multi probe setting, the probe other probes are synced to; defaults to 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import motive2GUI\n",
    "\n",
    "the_csvs = [r'A:\\store\\Bartul\\neuropixel\\test_100520\\No_sound\\Take 2020-05-10 12.31.15 PM_final.csv']\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\test_100520\\No_sound\\sync_df_100520_s1.pkl']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for the_csv, sync_pkl in zip(the_csvs, sync_pkls):\n",
    "    mtgClass = motive2GUI.Transformer(the_csv, sync_pkl)\n",
    "    mtgClass.csv_to_pkl()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 8]** Final processing steps before you start analyzing.\n",
    "\n",
    "1. create the head in the GUI (trackedpointdata_V3_5_LEDs.py version)\n",
    "2. load the spiking .mat files\n",
    "3. export everything as a .mat file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}