{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A pipeline for processing & successfully merging ephys and tracking data for further analyses.\n",
    "### author: github/bartulem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 1]** Merge Neuropixel sessions to run kilosort. This step is *optional*, you can skip it if you are interested in only one session.\n",
    "In the cell below, you determine the directories where the Neuropixel .bin files are (they should all be in one directory!), the desired name of the future merged file and its destination, the number of channels on the probe and whether to do the merging through the cmd prompt. This code outputs a .pkl file with information about changepoints of the merged sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concatenateNPX\n",
    "\n",
    "fileDirectories = [r'D:\\SGL_DATA\\test_concatenation']\n",
    "newFileNames = [r'D:\\SGL_DATA\\test_concatenation\\05022020_both_distal_g0_t0.imec0.ap.bin']\n",
    "cmdPrompt = 1\n",
    "nchan = 385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileDir, newFileName in zip(fileDirectories, newFileNames): \n",
    "    concatClass = concatenateNPX.concat(fileDir, newFileName)\n",
    "    concatClass.concatNPX(cmdPrompt=cmdPrompt, nchan=nchan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 2]** Run kilosort through Python.\n",
    "This assumes you are happy with *everything* in the config file. If you need to mess with that, either the code needs to change or you do this step in Matlab.\n",
    "If this doesn't bother you, then you should do the following:\n",
    "1. Install matlab.engine: https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html (as an admin!).\n",
    "2. Kilosort runs on all the .bin files in the given directory below. Make sure that this is what you want.\n",
    "2. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runKilosort\n",
    "\n",
    "fileDIR = r'D:\\SGL_DATA\\test_concatenation'\n",
    "kilosortDIR = r'A:\\group\\bartulm\\Kilosort2-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runKilosort.runKilo(fileDIR, kilosortDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 3]** Choose good clusters in Phy.\n",
    "1. Install Phy: https://github.com/cortex-lab/phy\n",
    "2. Navigate to the directory where kilosort was run, open powershell and type \"cmd\", followed by \"activate phy2\", followed by \"phy template-gui params.py\".\n",
    "3. Complete the manual curation (tutorial here: https://phy.readthedocs.io/en/latest/) and save your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 4]** Split clusters back into individual sessions and get spike times. This step should be completed also if you only spike sorted one session.\n",
    "Note that you set the number of channels on the probe, whether you have only one session or not, and the minimum number of spikes in one session to consider the cluster worthy of saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import saveSpikeTimes\n",
    "\n",
    "thedir = r'A:\\store\\Bartul\\neuropixel\\distal05022020'\n",
    "pklfile = '05022020_both_distal_g0_t0.imec0.ap.pkl'\n",
    "nchan = 385\n",
    "onesession = 1\n",
    "minspikes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstClass = saveSpikeTimes.sst(thedir)\n",
    "sstClass.splitClusters(onesession=onesession, minspikes=minspikes, nchan=nchan, pklfile=pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 5]** Read in the sync events (make sure the PC has enough memory to run this, say 64Gb RAM) and put them in a separate .txt file.\n",
    "You set the list with all the files whose sync events you'd like to read, and likewise the paths of future .txt files with that content. There's also the channel number parameter, which means the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import readSyncEvents\n",
    "\n",
    "npxList = [r'D:\\SGL_DATA\\05022020_session2_distal_g0\\05022020_session2_distal_g0_t0.imec0.ap.bin']\n",
    "npxTXTs = [r'A:\\store\\Bartul\\neuropixel\\05022020_distal_session2.txt']\n",
    "nchan = 385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npxFile, txtFile in zip(npxList, npxTXTs): \n",
    "    readClass = readSyncEvents.read(npxFile, txtFile)\n",
    "    readClass.readSE(nchan=nchan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next 4 steps are optional, and they should be completed if you want to know whether the systems are synced properly (Neuropixel, OptiTrack and Teensy). Otherwise jump to step 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 6]** Load the sync data from the .txt file(s) and estimate the frames of LEDon appearances in Motive to facilitate the search.\n",
    "You set the dirs where the .txt files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import estimateMotiveFrames\n",
    "\n",
    "txtdirs = [r'A:\\store\\Bartul\\neuropixel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emfClass = estimateMotiveFrames.emf(txtdirs)\n",
    "syncData = emfClass.estimateMF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 7]** Go to Motive and find the true LEDon appearances and place them into the appropriate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncData[r'A:\\store\\Bartul\\neuropixel']['05022020_distal_session2'].loc[:, 'Opti (true frame)'] = [0, 242, 13894, 23295, 33193, 40445, 62561, 67635, 67712, 73843, 74128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 8]** Do the regression to calculate 'Npx pred (sec)' and see how well it does.\n",
    "This outputs a .csv file with all the details of the computations and the empirical frame rate (first row, last column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syncRegression\n",
    "\n",
    "lrClass = syncRegression.lr(syncData)\n",
    "syncData = lrClass.linreg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 9]** Check the IMU sync with Npx and save the IMU file as a pickled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syncIMU\n",
    "\n",
    "txtsIMU = [r'A:\\store\\Bartul\\neuropixel\\scripts\\CoolTerm Capture 2020-02-12 14-43-06.txt']\n",
    "txtsNPX = [r'A:\\store\\Bartul\\neuropixel\\scripts\\12022020_distal_session1.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imuSClass = syncIMU.imuS(txtsIMU, txtsNPX)\n",
    "imuSClass.syncMilis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optional check steps stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 10]** Create .pkl file for GUI.\n",
    "1. If you haven't done so yet, label the rigid body and the body marker set in Motive (read the tutorial if you need).\n",
    "2. File > Export Tracking Data\n",
    "3. ***[important]*** Start Frame > Custom > 1st LED light frame, End Frame > Custom > Last LED light frame\n",
    "4. Put OFF in the following variables: (1) Unlabeled markers, (2) Rigid Bodies, (3) Rigid Body markers, (4) Bones, (5) Bone markers\n",
    "5. Click \"Export\" and you should create a .csv file\n",
    "6. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motive2GUI\n",
    "\n",
    "thecsvs = [r'A:\\store\\Bartul\\neuropixel\\distal05022020\\tracking\\Take 2020-02-05 04.01.13 PM (2).csv']\n",
    "thetxts = [r'A:\\store\\Bartul\\neuropixel\\05022020_distal_session2.txt']\n",
    "framerates = [r'A:\\store\\Bartul\\neuropixel\\05022020_distal_session2.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thecsv, thetxt, framerate in zip(thecsvs, thetxts, framerates): \n",
    "    mtgClass = motive2GUI.mtg(thecsv, thetxt)\n",
    "    mtgClass.csvTOpkl(framerate=framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 11]** Create the head in the GUI, load the spiking .mat files and export everything as a .mat file. Now you are ready to analyze!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
